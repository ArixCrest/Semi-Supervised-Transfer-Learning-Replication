pid: 1
default model wideresnetleaky 28 2
args: Namespace(alg='cr', alpha=0.1, bn_momentum=0.001, coef=0, consistency='ce', cutout_size=0.5, data_root='/workspace/data/minor1/data/SVHN', dataset='svhn', depth=28, ema_apply_wd=False, ema_teacher=False, ema_teacher_factor=0.999, ema_teacher_train=False, ema_teacher_warmup=False, epochs=10, eval_every=1, imprint=1, interleave=1, iteration=1000, kd_ent_class=1000, kd_threshold=0.7, l_batch_size=64, labeled_aug='WA', lambda_kd=0.5, lambda_mmd=0.5, lr=0.001, merge_one_batch=0, mmd_feat_table_l=128, mmd_feat_table_u=128, mmd_threshold=0.7, model='wideresnetleaky', momentum=0.9, n_imgs_per_epoch=6400, net_name='wideresnetleaky_28_2', num_cycles=0.49375, num_labels=1000, num_unlabels=-1, num_workers=1, out_dir='/workspace/data/minor1', per_epoch_steps=100, pretrained=1, pretrained_weight_path='/workspace/storage/minor1/codes/code/ckpt', reg_warmup=10, reg_warmup_iter=100, result_dir='/workspace/data/minor1/svhn@1000', resume=None, save_every=200, save_path='/workspace/data/minor1/svhn@1000/3', seed=1, sharpen=None, strong_aug=False, task_name='svhn@1000', temp_softmax=None, threshold=None, ul_batch_size=448, unlabeled_aug='WA', wa='t.t.f', warmup_iter=0, weight_decay=0.0005, widen_factor=2)
load dataset
number of :
 training data: 73257
 labeled data: 1000
 unlabeled data: 73257
 test data: 26032
labeled augmentation
Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=4)
    ToTensor()
    Normalize(mean=(0.481, 0.457, 0.408), std=(0.26, 0.253, 0.268))
)
unlabeled augmentation
Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=4)
    ToTensor()
    Normalize(mean=(0.481, 0.457, 0.408), std=(0.26, 0.253, 0.268))
)
==> creating model 'wideresnetleaky'
load pretrained model from /workspace/storage/minor1/codes/code/ckpt/wideresnetleaky_28_2.pth
Imprint the classifier of the model
==> creating model 'wideresnetleaky'
load pretrained model from /workspace/storage/minor1/codes/code/ckpt/wideresnetleaky_28_2.pth
Total params: 1.47M
DataParallel(
  (module): WideResnet_leaky(
    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (layer1): Sequential(
      (0): BasicBlockPreAct(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (downsample): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (layer2): Sequential(
      (0): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (downsample): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))
      )
      (1): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (layer3): Sequential(
      (0): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      )
      (1): BasicBlockPreAct(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): BasicBlockPreAct(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): BasicBlockPreAct(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (bn_last): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
    (relu_last): LeakyReLU(negative_slope=0.1, inplace=True)
    (pool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Linear(in_features=128, out_features=10, bias=True)
  )
)
training

Epoch: [0 | 10] LR: 0.001000 Epoch Time: 0.000 min
Epoch: 0, Learning Rate: 0.001, Train Loss: 1.142754020690918, Loss CE: 1.0954612648487092, Loss SSL: 0.0, Loss MMD: 0.013909800909459591, Loss KD: 0.16872357785701753, Labeled Acc: 0.62953125, Unlabeled Acc: 0.4683035917580128, Mask SSL: 0.0, Mask MMD: 0.5210267305374146, Mask KD: 0.94873046875, Test Loss: 1.3288731510535148, Test Acc.: 0.6070605406895985, Test Raw Acc.: 0.6070605406895985, Time: 36.98073744773865, 

Epoch: [1 | 10] LR: 0.000988 Epoch Time: 0.000 min
Epoch: 1, Learning Rate: 0.000987993594827769, Train Loss: 0.37564881294965746, Loss CE: 0.2786986140906811, Loss SSL: 0.0, Loss MMD: 0.01563305323012173, Loss KD: 0.17826734110713005, Labeled Acc: 0.9225, Unlabeled Acc: 0.6005134183168411, Mask SSL: 0.0, Mask MMD: 0.8805580139160156, Mask KD: 0.949511706829071, Test Loss: 1.5422968140539393, Test Acc.: 0.6197372460629065, Test Raw Acc.: 0.6197372460629065, Time: 37.19476389884949, 

Epoch: [2 | 10] LR: 0.000952 Epoch Time: 0.000 min
Epoch: 2, Learning Rate: 0.0009522626868413953, Train Loss: 0.17838533461093903, Loss CE: 0.0808024525642395, Loss SSL: 0.0, Loss MMD: 0.015633105169981718, Loss KD: 0.17953265726566314, Labeled Acc: 0.9815625, Unlabeled Acc: 0.6152455639839173, Mask SSL: 0.0, Mask MMD: 0.9530582427978516, Mask KD: 0.9494140148162842, Test Loss: 1.453704184597815, Test Acc.: 0.6497387828897243, Test Raw Acc.: 0.6497387828897243, Time: 36.72642683982849, 

Epoch: [3 | 10] LR: 0.000894 Epoch Time: 0.000 min
Epoch: 3, Learning Rate: 0.0008936652755577915, Train Loss: 0.1296203301846981, Loss CE: 0.03355586946010589, Loss SSL: 0.0, Loss MMD: 0.015641658492386343, Loss KD: 0.17648726165294648, Labeled Acc: 0.99453125, Unlabeled Acc: 0.6263169914484024, Mask SSL: 0.0, Mask MMD: 0.9670312404632568, Mask KD: 0.9496874809265137, Test Loss: 1.4849881856955849, Test Acc.: 0.6550783648326782, Test Raw Acc.: 0.6550783648326782, Time: 37.40087890625, 

Epoch: [4 | 10] LR: 0.000814 Epoch Time: 0.000 min
Epoch: 4, Learning Rate: 0.000813608449500787, Train Loss: 0.10983968786895275, Loss CE: 0.016026329547166825, Loss SSL: 0.0, Loss MMD: 0.015633753910660745, Loss KD: 0.17199296295642852, Labeled Acc: 0.99921875, Unlabeled Acc: 0.6325446689128875, Mask SSL: 0.0, Mask MMD: 0.9716516137123108, Mask KD: 0.9507421851158142, Test Loss: 1.4226605363176437, Test Acc.: 0.668869083910979, Test Raw Acc.: 0.668869083910979, Time: 36.92143964767456, 

Epoch: [5 | 10] LR: 0.000714 Epoch Time: 0.000 min
Epoch: 5, Learning Rate: 0.0007140145980512682, Train Loss: 0.10434715196490288, Loss CE: 0.012296097571961581, Loss SSL: 0.0, Loss MMD: 0.01565098932944238, Loss KD: 0.16845111951231956, Labeled Acc: 0.99921875, Unlabeled Acc: 0.6344643115997315, Mask SSL: 0.0, Mask MMD: 0.9740402102470398, Mask KD: 0.9495312571525574, Test Loss: 1.4591511167773603, Test Acc.: 0.6641057157487171, Test Raw Acc.: 0.6641057157487171, Time: 36.83270502090454, 

Epoch: [6 | 10] LR: 0.000597 Epoch Time: 0.000 min
Epoch: 6, Learning Rate: 0.000597275249475567, Train Loss: 0.09995076835155486, Loss CE: 0.009810855924151839, Loss SSL: 0.0, Loss MMD: 0.015651823785156012, Loss KD: 0.16462800040841102, Labeled Acc: 0.99953125, Unlabeled Acc: 0.6379241347312927, Mask SSL: 0.0, Mask MMD: 0.9751560091972351, Mask KD: 0.9528710842132568, Test Loss: 1.4287966497851503, Test Acc.: 0.6684081133480224, Test Raw Acc.: 0.6684081133480224, Time: 37.20040464401245, 

Epoch: [7 | 10] LR: 0.000466 Epoch Time: 0.000 min
Epoch: 7, Learning Rate: 0.00046619364361076787, Train Loss: 0.09756990373134614, Loss CE: 0.008566526416689157, Loss SSL: 0.0, Loss MMD: 0.01565970905125141, Loss KD: 0.16234704554080964, Labeled Acc: 0.9996875, Unlabeled Acc: 0.6357143127918243, Mask SSL: 0.0, Mask MMD: 0.9750672578811646, Mask KD: 0.9511327743530273, Test Loss: 1.4441837058451252, Test Acc.: 0.6671788569381798, Test Raw Acc.: 0.6671788569381798, Time: 37.78039360046387, 

Epoch: [8 | 10] LR: 0.000324 Epoch Time: 0.000 min
Epoch: 8, Learning Rate: 0.0003239174181981494, Train Loss: 0.0952129926532507, Loss CE: 0.007099250350147485, Loss SSL: 0.0, Loss MMD: 0.015653505632653834, Loss KD: 0.16057397916913033, Labeled Acc: 0.99984375, Unlabeled Acc: 0.634508957862854, Mask SSL: 0.0, Mask MMD: 0.9752010107040405, Mask KD: 0.9511327743530273, Test Loss: 1.4371087485174496, Test Acc.: 0.6675245847230171, Test Raw Acc.: 0.6675245847230171, Time: 37.079100370407104, 

Epoch: [9 | 10] LR: 0.000174 Epoch Time: 0.000 min
Epoch: 9, Learning Rate: 0.00017386302525507091, Train Loss: 0.09391364574432373, Loss CE: 0.00644648123998195, Loss SSL: 0.0, Loss MMD: 0.015659872321411968, Loss KD: 0.15927445709705354, Labeled Acc: 1.0, Unlabeled Acc: 0.6368973499536514, Mask SSL: 0.0, Mask MMD: 0.9755800366401672, Mask KD: 0.9500976204872131, Test Loss: 1.435534028239095, Test Acc.: 0.667332514122211, Test Raw Acc.: 0.667332514122211, Time: 36.622453689575195, 
mean test acc. over last 1 checkpoints: 0.667332514122211
median test acc. over last 1 checkpoints: 0.667332514122211
mean test acc. over last 10 checkpoints: 0.6535033803266034
median test acc. over last 10 checkpoints: 0.6656422863434485
mean test acc. over last 20 checkpoints: 0.6535033803266034
median test acc. over last 20 checkpoints: 0.6656422863434485
mean test acc. over last 50 checkpoints: 0.6535033803266034
median test acc. over last 50 checkpoints: 0.6656422863434485
