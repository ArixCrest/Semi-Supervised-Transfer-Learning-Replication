pid: 1
default model wideresnetleaky 28 2
args: Namespace(alg='cr', alpha=0.1, bn_momentum=0.001, coef=0, consistency='ce', cutout_size=0.5, data_root='/workspace/data/minor1/data', dataset='cifar10', depth=28, ema_apply_wd=False, ema_teacher=False, ema_teacher_factor=0.999, ema_teacher_train=False, ema_teacher_warmup=False, epochs=10, eval_every=1, imprint=1, interleave=1, iteration=1000, kd_ent_class=1000, kd_threshold=0.7, l_batch_size=64, labeled_aug='WA', lambda_kd=0.0, lambda_mmd=0.0, lr=0.0001, merge_one_batch=0, mmd_feat_table_l=128, mmd_feat_table_u=128, mmd_threshold=0.7, model='wideresnetleaky', momentum=0.9, n_imgs_per_epoch=6400, net_name='wideresnetleaky_28_2', num_cycles=0.49375, num_labels=200, num_unlabels=-1, num_workers=1, out_dir='/workspace/data/minor1', per_epoch_steps=100, pretrained=1, pretrained_weight_path='/workspace/storage/minor1/codes/code/ckpt', reg_warmup=10, reg_warmup_iter=100, result_dir='/workspace/data/minor1/cifar10@200', resume=None, save_every=200, save_path='/workspace/data/minor1/cifar10@200/1', seed=1, sharpen=None, strong_aug=False, task_name='cifar10@200', temp_softmax=None, threshold=None, ul_batch_size=448, unlabeled_aug='WA', wa='t.t.f', warmup_iter=0, weight_decay=0.0005, widen_factor=2)
load dataset
number of :
 training data: 10000
 labeled data: 200
 unlabeled data: 10000
 test data: 10000
labeled augmentation
Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=4)
    ToTensor()
    Normalize(mean=(0.481, 0.457, 0.408), std=(0.26, 0.253, 0.268))
)
unlabeled augmentation
Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=4)
    ToTensor()
    Normalize(mean=(0.481, 0.457, 0.408), std=(0.26, 0.253, 0.268))
)
==> creating model 'wideresnetleaky'
load pretrained model from /workspace/storage/minor1/codes/code/ckpt/wideresnetleaky_28_2.pth
Imprint the classifier of the model
Total params: 1.47M
DataParallel(
  (module): WideResnet_leaky(
    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (layer1): Sequential(
      (0): BasicBlockPreAct(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (downsample): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (layer2): Sequential(
      (0): BasicBlockPreAct(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (downsample): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))
      )
      (1): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (layer3): Sequential(
      (0): BasicBlockPreAct(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      )
      (1): BasicBlockPreAct(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): BasicBlockPreAct(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): BasicBlockPreAct(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (bn_last): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
    (relu_last): LeakyReLU(negative_slope=0.1, inplace=True)
    (pool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Linear(in_features=128, out_features=10, bias=True)
  )
)
training

Epoch: [0 | 10] LR: 0.000100 Epoch Time: 0.000 min
Epoch: 0, Learning Rate: 0.0001, Train Loss: 0.18475959803909064, Loss CE: 0.18475959803909064, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 0.95734375, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.9213160405158997, Test Acc.: 0.7386999999046325, Test Raw Acc.: 0.7386999999046325, Time: 39.05417728424072, 

Epoch: [1 | 10] LR: 0.000099 Epoch Time: 0.000 min
Epoch: 1, Learning Rate: 9.87993594827769e-05, Train Loss: 0.055662438217550514, Loss CE: 0.055662438217550514, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 0.99921875, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.8949116370201111, Test Acc.: 0.7476000000953674, Test Raw Acc.: 0.7476000000953674, Time: 40.43705892562866, 

Epoch: [2 | 10] LR: 0.000095 Epoch Time: 0.000 min
Epoch: 2, Learning Rate: 9.522626868413954e-05, Train Loss: 0.03436069902032614, Loss CE: 0.03436069902032614, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 0.99984375, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.8162526976585388, Test Acc.: 0.7674000005722046, Test Raw Acc.: 0.7674000005722046, Time: 39.96709060668945, 

Epoch: [3 | 10] LR: 0.000089 Epoch Time: 0.000 min
Epoch: 3, Learning Rate: 8.936652755577916e-05, Train Loss: 0.025492382775992153, Loss CE: 0.025492382775992153, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 0.99984375, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.7467841021537781, Test Acc.: 0.7821999994277954, Test Raw Acc.: 0.7821999994277954, Time: 41.29294228553772, 

Epoch: [4 | 10] LR: 0.000081 Epoch Time: 0.000 min
Epoch: 4, Learning Rate: 8.13608449500787e-05, Train Loss: 0.021730881277471782, Loss CE: 0.021730881277471782, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 1.0, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.6923255431175231, Test Acc.: 0.7965999999046326, Test Raw Acc.: 0.7965999999046326, Time: 40.5937237739563, 

Epoch: [5 | 10] LR: 0.000071 Epoch Time: 0.000 min
Epoch: 5, Learning Rate: 7.140145980512682e-05, Train Loss: 0.01755925768055022, Loss CE: 0.01755925768055022, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 1.0, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.6440985661506653, Test Acc.: 0.8080000002861023, Test Raw Acc.: 0.8080000002861023, Time: 40.846901178359985, 

Epoch: [6 | 10] LR: 0.000060 Epoch Time: 0.000 min
Epoch: 6, Learning Rate: 5.97275249475567e-05, Train Loss: 0.015727664204314352, Loss CE: 0.015727664204314352, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 1.0, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.6039634251594543, Test Acc.: 0.8167000007629395, Test Raw Acc.: 0.8167000007629395, Time: 40.05006742477417, 

Epoch: [7 | 10] LR: 0.000047 Epoch Time: 0.000 min
Epoch: 7, Learning Rate: 4.661936436107679e-05, Train Loss: 0.015148826288059353, Loss CE: 0.015148826288059353, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 1.0, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.5721654418945312, Test Acc.: 0.8241999993324279, Test Raw Acc.: 0.8241999993324279, Time: 39.47662425041199, 

Epoch: [8 | 10] LR: 0.000032 Epoch Time: 0.000 min
Epoch: 8, Learning Rate: 3.239174181981494e-05, Train Loss: 0.01358285809867084, Loss CE: 0.01358285809867084, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 1.0, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.5469554821968079, Test Acc.: 0.8291999999046326, Test Raw Acc.: 0.8291999999046326, Time: 40.79298782348633, 

Epoch: [9 | 10] LR: 0.000017 Epoch Time: 0.000 min
Epoch: 9, Learning Rate: 1.7386302525507093e-05, Train Loss: 0.013608084470033645, Loss CE: 0.013608084470033645, Loss SSL: 0, Loss MMD: 0, Loss KD: 0, Labeled Acc: 1.0, Unlabeled Acc: 0, Mask SSL: 0, Mask MMD: 0, Mask KD: 0, Test Loss: 0.5268765009880066, Test Acc.: 0.8332, Test Raw Acc.: 0.8332, Time: 38.894757986068726, 
mean test acc. over last 1 checkpoints: 0.8332
median test acc. over last 1 checkpoints: 0.8332
mean test acc. over last 10 checkpoints: 0.7943800000190735
median test acc. over last 10 checkpoints: 0.8023000000953675
mean test acc. over last 20 checkpoints: 0.7943800000190735
median test acc. over last 20 checkpoints: 0.8023000000953675
mean test acc. over last 50 checkpoints: 0.7943800000190735
median test acc. over last 50 checkpoints: 0.8023000000953675
